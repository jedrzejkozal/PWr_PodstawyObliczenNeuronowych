\documentclass[12pt]{article}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{array}
\usepackage{pbox}
\usepackage{amsmath}

\newcommand\tab[1][1cm]{\hspace*{#1}}

\title{Dokumentacja projektowa}
\date{2018-03-18}
\author{Jędrzej Kozal}

\begin{document}

\begin{titlepage}
	\centering
	\includegraphics[width=0.25\textwidth]{logo_pol_wroclaw.png}\par\vspace{1cm}
	{\scshape\LARGE Politechnika Wrocławska \par}
	\vspace{1cm}
	{\scshape\Large Podstawy Obliczeń Neuronowych\par}
	\vspace{1.5cm}
	{\huge\bfseries Sieci radialne w predykcji procesów medycznych - choroba Parkinsona \par}
	\vspace{2cm}
	{\Large\itshape Filip Guzy\par}
	{\Large\itshape Jędrzej Kozal\par}

	\vfill
	prowadzący\par
	Dr inż.~Edward \textsc{Puchała}

	\vfill

% Bottom of the page
	{\large \today\par}
\end{titlepage}

\tableofcontents
\newpage


\section{Wstęp}

\subsection{Cel projektu}

Celem projektu było zbadanie skuteczności radialnych sieci neuronowych w predykcji przebiegu choroby Parkinsona.

\subsection{Wykorzystane narzędzia}

Do realizacji projektu wykorzystano środowisko Matlab, w tym Deep Learning Toolbox zawierający funkcje niezbędne do tworzenia radialnych sieci neuronowych oraz dane ze zbioru uczącego UCI Oxford Parkinson's Disease Telemonitoring Dataset, udostępnionego przez autorów do celów naukowo-badawczych \cite{zbioruczacy}. 

\subsection{Aspekt medyczny}

Parkinson jest zwyrodnieniową chorobą ośrodkowego układu nerwowego. Występuje ona najczęściej u osób starszych, głównie mężczyzn i rozwija się przez kilkanaście lat. Jej objawami są między innymi: osłabienie, zmęczenie, spowolnienie ruchowe, drżenie mięśni czy też kłopoty z wykonywaniem codziennych czynności, takich jak wstawanie, mycie, jedzenie, ubieranie się.  Objawy te oraz sposób rozwoju choroby pozwalają na stworzenie systemów predykcyjnych umożliwiających ciągłe monitorowanie stanu zdrowia pacjentów. Zbiór uczący użyty w projekcie wykorzystuje pomiary głosu pacjentów wykonane przez urządzenie telemedyczne służące do śledzenia przebiegu choroby w sześciomiesięcznym przedziale czasu. Dla pojedynczego pacjenta zawiera on parametry takie jak: identyfikator, wiek oraz płeć, interwały czasowe wykonanych pomiarów, szesnaście parametrów opisujących nagrany dźwięk, a także parametry wynikowe UPDRS (Unified Parkinson's Disease Rating Scale) opisujące postęp choroby. W zbiorze znajdują się dane zawierające informację o 42 różnych pacjentach, po około 140 pomiarów dla pojedynczej osoby, co łącznie daje około 5000 rekordów.

\section{Zarys podstaw teoretycznych}

\subsection{Topologia radialnych sieci neuronowych}

Radialne sieci neuronowe są specjalną odmianą perceptronów wielowarstwowych. Tak jak one realizują bowiem odwzorowanie zbioru wejściowego w wyjściowy, robią to jednak poprzez dopasowanie wielu pojedynczych funkcji aproksymujących do wartości zadanych. Odwzorowania takie ważne są tylko w wąskim obszarze przestrzeni wielowymiarowej, zatem ich suma jest odwzorowaniem pełnego zbioru danych. Neurony warstwy ukrytej w sieciach radialnych realizują funkcję zmieniającą się radialnie wokół wybranego centrum \textsl{c} i przyjmującą wartości niezerowe jedynie w otoczeniu tego punktu. Realizację taką przedstawia poniższy rysunek:

\begin{figure}[h!]
\centering
	\includegraphics[width=0.5\textwidth]{rbf-gauss.jpeg}\par\vspace{1cm}
\caption{Realizacja funkcji zmieniającej się radialnie}
	\label{fig:features}
\end{figure}

Funkcje takie, nazywane radialnymi funkcjami bazowymi, przyjmują postać: 

\[ \varphi(x) = \varphi(||x-c||) \]

Rolę neuronu ukrytego można zatem sprowadzić do odwzorowania radialnego przestrzeni wokół jednego zadanego punktu lub grupy takich punktów stanowiących klaster. Odwzorowanie całej przestrzeni wielowymiarowej przez neurony warstwy wyjściowej jest więc możliwe dzięki superpozycji sygnałów pochodzących od wszystkich neuronów ukrytych. Dobór liczby neuronów warstwy zależy ściśle od przyjętego błędu, przy czym poszczególne neurony dodawane są iteracyjnie, po jednym neuronie w każdej iteracji, aż do osiągnięcia pożądanego błędu średniokwadratowego. Maksymalna liczba neuronów w warstwie ukrytej nie może przekroczyć  liczby wektorów podanych na wejście sieci. Typowa sieć radialna jest modelem zawierającym warstwę wejściową przyjmującą sygnały opisywane wektorem wejściowym \textbf{x}, warstwę ukrytą neuronów radialnych oraz warstwę wyjściową złożoną z neuronów liniowych. Przykład takiej topologii przestawiono na poniższym rysunku:

\begin{figure}[h!]
\centering
	\includegraphics[width=0.5\textwidth]{rbf.png}\par\vspace{1cm}
\caption{Topologia sieci radialnej}
	\label{fig:features}
\end{figure}

\subsection{Wagi neuronów w sieci radialnej}

Przyjmując \textsl{p} neuronów ukrytych połączonych wagami \textsl{$w_i$} z liniowymi neuronami wyjściowymi oraz model sieci radialnej o jednym wyjściu i \textsl{p} parach uczących ($x_i$, $d_i$), a także zakładając \textsl{p} centrów umieszczonych w kolejnych wektorach $x_i$ (tj. $c_i = x_i$) otrzymujemy układ równań liniowych względem wag $w_i$. Układ ten można zapisać w postaci macierzowej:

\[
\begin{bmatrix}
    \varphi_{11}  & \varphi_{12}  & \dots & \varphi_{1p} \\
    \varphi_{21}  & \varphi_{22} &  \dots & \varphi_{2p} \\
    \hdotsfor{4} \\
    \varphi_{p1}  & \varphi_{p2} &  \dots & \varphi_{pp}
\end{bmatrix}
\begin{bmatrix}
	w_1 \\
	w_2 \\
	\dots \\
	w_p
\end{bmatrix}
=
\begin{bmatrix}
	d_1 \\
	d_2 \\
	\dots \\
	d_p
\end{bmatrix}
\]

gdzie:

\[ \varphi_{ji} = \varphi(||x_j-x_i||) \]

dotyczy funkcji radialnej w centrum $x_i$ przy wektorze wymuszającym $x_j$. Oznaczając macierz o elementach $\varphi_{ji}$ jako $\Phi$ i przyjmując oznaczenia wektorów $w = [w_1, w_2, ..., w_p]^T$, $d = [d_1, d_2, ..., d_p]^T$ równanie może być zapisywane w postaci macierzowej:

\[ \Phi w = d \]

Istnieje rozwiązanie równania w postaci:

\[ w = \Phi^{-1} d \]

pozwalające określić wektor wag \textsl{w} neuronu wyjściowego sieci.

\subsection{Algorytmy uczenia sieci radialnych}

Możemy wyróżnić trzy grupy algorytmów uczących mających zastosowanie w procesach uczenia sieci radialnych:

\begin{enumerate}

\item Algorytmy probabilistyczne doboru parametrów funkcji radialnych
\item Algorytmy hybrydowe 
\item Algorytmy oparte na wstecznej propagacji błędu

\end{enumerate}

W projekcie zastosowano algorytm uczenia oparty na mechanizmie wstecznej propagacji błędu. Podobnie jak w sieciach sigmoidalnych, jego podstawę stanowi funkcja celu definiowana dla wszystkich \textsl{p} par neuronów uczących ($x_j$, $d_j$):

\[ E = \frac{1}{2} \sum_{j=1}^{p} [\sum_{i=0}^{K} w_i\varphi_{i}(x_{j} - d_j)]^2 \]

którą to, zakładając jeden wzorzec uczący ($x$, $d$) można uprościć do postaci:

\[ E = \frac{1}{2}  [\sum_{i=0}^{K} w_i\varphi_{i}(x) - d]^2 \]

\newpage
\section{Osiągnięte rezultaty}

1) 13.10.2018 \\


number\_of\_patients = 42\\
traning\_set\_size = 30\\
test\_set\_size = 12;\\

eg = 0.1; % sum-squared error goal\\
sc = 1;    % spread constant

Zmniejszenie liczby parametrów powoduje skrócenie czasu uczenia sieci, ale dalej pozostaje overfiting. Dodanie wieku i płci do parametrów na wejściu sieci spowodowało znaczne przyśpieszenie uczenia sieci. Dla parametrów: test\_time, Jitter(%), Shimmer(dB) sieć nie osiągała dostatecznie niskich wartości funkcji celu mimo dużej ilości epok. Po dodaniu age i sex sieć do parametrów wejściowych uzyskano znacząco przyśpieszono proces uczenia sieci. Zmniejszenie progu kwadratowej funkcji celu z 0.1 do 0.05 nie dało znaczących rezultatów.

Wyłączenie czasu z wektora wejściowego i zmiana wybierania zbioru testowego na 24 pierwsze próbki z nieposorotwanych danych z bazy UCI spowodowało podwyższenie progu wartości średnio kwadratowego błędu do 8, co znacząco pogorszyło dopasowanie nawet dla zbioru uczącego.





\begin{figure}
\centering
	\includegraphics[width=0.90\textwidth]{fig1.jpg}\par\vspace{1cm}
\caption{Rezultaty dla zbioru uczącego}
	\label{fig:features}
\end{figure}

\begin{figure}
\centering
	\includegraphics[width=0.90\textwidth]{fig2.jpg}\par\vspace{1cm}
\caption{Rezultaty dla zbioru testowego}
	\label{fig:features}
\end{figure}

\section{Wnioski}

\newpage
\begin{thebibliography}{9}

\bibitem{zbioruczacy}
A Tsanas, MA Little, PE McSharry, LO Ramig (2009) 
'Accurate telemonitoring of Parkinson’s disease progression by non-invasive speech tests', 
IEEE Transactions on Biomedical Engineering (to appear). 
\\\texttt{https://archive.ics.uci.edu/ml/datasets/Parkinsons+\\Telemonitoring}

\bibitem{zbior-uczacy1}
Little MA, McSharry PE, Hunter EJ, Ramig LO (2009), 
'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', 
IEEE Transactions on Biomedical Engineering, 56(4):1015-1022 

\bibitem{zbior-uczacy2}
Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. 
'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', 
BioMedical Engineering OnLine, 26 June 2007

\bibitem{Osowski ujecie algorytmiczne}
Stanisław Osowski.
\textit{Sieci Neuronowe w ujęciu algorytmicznym}
Wydawnictwo Naukowo-Techniczne, Warszawa 1996

\bibitem{Osowski przetwarzanie informacji}
Stanisław Osowski.
\textit{Sieci Neuronowe do przetwarzania informacji}
Oficyna Wydawnicza Politechniki Warszawskiej, Warszawa 2006

\bibitem{Spread Constant}
Hongfa Wang, Xinai Xu, Zhejiang
Water Conservancy and Hydropower College
Determination of Spread Constant in RBF Neural Network by Genetic
Algorithm 
\textit{http://www.globalcis.org/ijact/ppl/IJACT3017PPL.pdf}

\bibitem{matlab}
Oficjalna dokumentacja Mathworks Deep Learning Toolbox. 
\\\texttt{https://www.mathworks.com/help/deeplearning/examples/radial-\\basis-approximation.html}

\bibitem{owards Data Sience}
Towards Data Science blog
\\\texttt{https://towardsdatascience.com/radial-basis-functions-neural-\\networks-all-we-need-to-know-9a88cc053448}


\end{thebibliography}
\newpage

\listoffigures
\newpage

\end{document}