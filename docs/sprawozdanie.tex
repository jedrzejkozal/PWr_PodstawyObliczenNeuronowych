\documentclass[12pt]{article}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{float}
\usepackage{caption}
\usepackage{array}
\usepackage{pbox}
\usepackage{amsmath}

\newcommand\tab[1][1cm]{\hspace*{#1}}

\title{Dokumentacja projektowa}
\date{2018-03-18}
\author{Jędrzej Kozal}

\begin{document}

\begin{titlepage}
	\centering
	\includegraphics[width=0.25\textwidth]{logo_pol_wroclaw.png}\par\vspace{1cm}
	{\scshape\LARGE Politechnika Wrocławska \par}
	\vspace{1cm}
	{\scshape\Large Podstawy Obliczeń Neuronowych\par}
	\vspace{1.5cm}
	{\huge\bfseries Sieci radialne w predykcji procesów medycznych - choroba Parkinsona \par}
	\vspace{2cm}
	{\Large\itshape Filip Guzy\par}
	{\Large\itshape Jędrzej Kozal\par}

	\vfill
	prowadzący\par
	Dr inż.~Edward \textsc{Puchała}

	\vfill

% Bottom of the page
	{\large \today\par}
\end{titlepage}

\tableofcontents
\newpage


\section{Wstęp}

\subsection{Cel projektu}

Celem projektu było zbadanie skuteczności radialnych sieci neuronowych w predykcji przebiegu choroby Parkinsona.

\subsection{Wykorzystane narzędzia}

Do realizacji projektu wykorzystano środowisko Matlab, w tym Deep Learning Toolbox zawierający funkcje niezbędne do tworzenia radialnych sieci neuronowych oraz dane ze zbioru uczącego UCI Oxford Parkinson's Disease Telemonitoring Dataset, udostępnionego przez autorów do celów naukowo-badawczych \cite{zbioruczacy}. 

\subsection{Aspekt medyczny}

Parkinson jest zwyrodnieniową chorobą ośrodkowego układu nerwowego. Występuje ona najczęściej u osób starszych, głównie mężczyzn i rozwija się przez kilkanaście lat. Jej objawami są między innymi: osłabienie, zmęczenie, spowolnienie ruchowe, drżenie mięśni czy też kłopoty z wykonywaniem codziennych czynności, takich jak wstawanie, mycie, jedzenie, ubieranie się.  Objawy te oraz sposób rozwoju choroby pozwalają na stworzenie systemów predykcyjnych umożliwiających ciągłe monitorowanie stanu zdrowia pacjentów. Zbiór uczący użyty w projekcie wykorzystuje pomiary głosu pacjentów wykonane przez urządzenie telemedyczne służące do śledzenia przebiegu choroby w sześciomiesięcznym przedziale czasu. Dla pojedynczego pacjenta zawiera on parametry takie jak: identyfikator, wiek oraz płeć, interwały czasowe wykonanych pomiarów, szesnaście parametrów opisujących nagrany dźwięk, a także parametry wynikowe UPDRS (Unified Parkinson's Disease Rating Scale) opisujące postęp choroby. W zbiorze znajdują się dane zawierające informację o 42 różnych pacjentach, po około 140 pomiarów dla pojedynczej osoby, co łącznie daje około 5000 rekordów.

\section{Zarys podstaw teoretycznych}

\subsection{Topologia radialnych sieci neuronowych}

Radialne sieci neuronowe są specjalną odmianą perceptronów wielowarstwowych. Tak jak one realizują bowiem odwzorowanie zbioru wejściowego w wyjściowy, robią to jednak poprzez dopasowanie wielu pojedynczych funkcji aproksymujących do wartości zadanych. Odwzorowania takie ważne są tylko w wąskim obszarze przestrzeni wielowymiarowej, zatem ich suma jest odwzorowaniem pełnego zbioru danych. Neurony warstwy ukrytej w sieciach radialnych realizują funkcję zmieniającą się radialnie wokół wybranego centrum \textsl{c} i przyjmującą wartości niezerowe jedynie w otoczeniu tego punktu. Realizację taką przedstawia poniższy rysunek:

\begin{figure}[h!]
\centering
	\includegraphics[width=0.5\textwidth]{rbf-gauss.jpeg}\par\vspace{1cm}
\caption{Realizacja funkcji zmieniającej się radialnie}
	\label{fig:features}
\end{figure}

Funkcje takie, nazywane radialnymi funkcjami bazowymi, przyjmują postać: 

\[ \varphi(x) = \varphi(||x-c||) \]

Rolę neuronu ukrytego można zatem sprowadzić do odwzorowania radialnego przestrzeni wokół jednego zadanego punktu lub grupy takich punktów stanowiących klaster. Odwzorowanie całej przestrzeni wielowymiarowej przez neurony warstwy wyjściowej jest więc możliwe dzięki superpozycji sygnałów pochodzących od wszystkich neuronów ukrytych. Dobór liczby neuronów warstwy zależy ściśle od przyjętego błędu, przy czym poszczególne neurony dodawane są iteracyjnie, po jednym neuronie w każdej iteracji, aż do osiągnięcia pożądanego błędu średniokwadratowego. Maksymalna liczba neuronów w warstwie ukrytej nie może przekroczyć  liczby wektorów podanych na wejście sieci. Typowa sieć radialna jest modelem zawierającym warstwę wejściową przyjmującą sygnały opisywane wektorem wejściowym \textbf{x}, warstwę ukrytą neuronów radialnych oraz warstwę wyjściową złożoną z neuronów liniowych. Przykład takiej topologii przestawiono na poniższym rysunku:

\begin{figure}[h!]
\centering
	\includegraphics[width=0.5\textwidth]{rbf.png}\par\vspace{1cm}
\caption{Topologia sieci radialnej}
	\label{fig:features}
\end{figure}

\subsection{Wagi neuronów w sieci radialnej}

Przyjmując \textsl{p} neuronów ukrytych połączonych wagami \textsl{$w_i$} z liniowymi neuronami wyjściowymi oraz model sieci radialnej o jednym wyjściu i \textsl{p} parach uczących ($x_i$, $d_i$), a także zakładając \textsl{p} centrów umieszczonych w kolejnych wektorach $x_i$ (tj. $c_i = x_i$) otrzymujemy układ równań liniowych względem wag $w_i$. Układ ten można zapisać w postaci macierzowej:

\[
\begin{bmatrix}
    \varphi_{11}  & \varphi_{12}  & \dots & \varphi_{1p} \\
    \varphi_{21}  & \varphi_{22} &  \dots & \varphi_{2p} \\
    \hdotsfor{4} \\
    \varphi_{p1}  & \varphi_{p2} &  \dots & \varphi_{pp}
\end{bmatrix}
\begin{bmatrix}
	w_1 \\
	w_2 \\
	\dots \\
	w_p
\end{bmatrix}
=
\begin{bmatrix}
	d_1 \\
	d_2 \\
	\dots \\
	d_p
\end{bmatrix}
\]

gdzie:

\[ \varphi_{ji} = \varphi(||x_j-x_i||) \]

dotyczy funkcji radialnej w centrum $x_i$ przy wektorze wymuszającym $x_j$. Oznaczając macierz o elementach $\varphi_{ji}$ jako $\Phi$ i przyjmując oznaczenia wektorów $w = [w_1, w_2, ..., w_p]^T$, $d = [d_1, d_2, ..., d_p]^T$ równanie może być zapisywane w postaci macierzowej:

\[ \Phi w = d \]

Istnieje rozwiązanie równania w postaci:

\[ w = \Phi^{-1} d \]

pozwalające określić wektor wag \textsl{w} neuronu wyjściowego sieci.

\subsection{Algorytmy uczenia sieci radialnych}

Możemy wyróżnić trzy grupy algorytmów uczących mających zastosowanie w procesach uczenia sieci radialnych:

\begin{enumerate}

\item Algorytmy probabilistyczne doboru parametrów funkcji radialnych
\item Algorytmy hybrydowe 
\item Algorytmy oparte na wstecznej propagacji błędu

\end{enumerate}

W projekcie zastosowano algorytm uczenia oparty na mechanizmie wstecznej propagacji błędu. Podobnie jak w sieciach sigmoidalnych, jego podstawę stanowi funkcja celu definiowana dla wszystkich \textsl{p} par neuronów uczących ($x_j$, $d_j$):

\[ E = \frac{1}{2} \sum_{j=1}^{p} [\sum_{i=0}^{K} w_i\varphi_{i}(x_{j} - d_j)]^2 \]

którą to, zakładając jeden wzorzec uczący ($x$, $d$) można uprościć do postaci:

\[ E = \frac{1}{2}  [\sum_{i=0}^{K} w_i\varphi_{i}(x) - d]^2 \]

Należy przyjąć odpowiednie oznaczenia wyjść poszczególnych neuronów:

\begin{flushleft}
$x_m$ - wartość m-tego wejścia \newline
$h_{ij}$ - wartości (i,j) macierzy wyjść neuronów ukrytych, gdzie i - numer warstwy ukrytej, j - numer neuronu w warstwie \newline
$y_p$ - wartość p-tego wyjścia \newline
\end{flushleft}


Zależności pomiędzy warstwami neuronów można przedstawić jako: \newline

\begin{flushleft}
$h_{1j} = f(\sum_{m=1}^{n} w_{mj}x_m)$ \newline
$h_{2j} = f(\sum_{m=1}^{n} w_{mj}h_{1j})$ \newline
... \newline
$h_{nj} = f(\sum_{m=1}^{n} w_{mj}h_{(n-1)j})$ \newline
$y_p = f(\sum_{m=1}^{n} w_{mj}h_{nj})$ \newline
\end{flushleft}

Kolejne kroki algorytmu można opisać następująco:

\begin{enumerate}

\item \textsl{podanie przykładu ze zbioru uczącego na wejście sieci,}

\item \textsl{wyznaczenie wartości wyjść warstwy wyjściowej,}

\item \textsl{obliczenie wektora błędu - różnicy pomiędzy wartościami założonymi, a otrzymanymi,}

\item \textsl{obliczenie sumy kwadratów elementów wektora błędu,}

\item \textsl{sprawdzenie, czy próg błędu został osiągnięty - warunek stopu algorytmu,}

\item \textsl{wykonanie propagacji wstecznej,}

\item \textsl{aktualizacja wag pomiędzy warstwami ukrytą i wejściową, a następnie pomiędzy wejściową i ukrytą.}

\end{enumerate}

\newpage
\section{Zbiór uczący}

\subsection{Opis zawartości zbioru}

Do realizacji zadania wykorzystano zbiór uczący Parkinsons Telemonitoring Data Set dostępny w repozytorium UCI. Zbiór zawiera pomiary głosów pacjentów we wczesnym etapie choroby Parkinsona. Na bazę składa się 5875 próbek pobranych dla 42 pacjentów.

\subsection{Opis parametrów}

Kolumny z danymi pacjentów zawierają kolejno:
\begin{itemize}
	\item id pacjenta
	\item wiek pacjenta
	\item płeć pacjenta (0 - mężczyzna, 1 - kobieta)
	\item czas od zgłoszenia się do testów
	\item UPDRS motoryczny (Unified Parkinson's Disease Rating Scale)
	\item UPDRS całkowity
	\item Jitter(\%), Jitter(Abs), Jitter:RAP, Jitter:PPQ5, Jitter:DDP - pomiary zmiany częstotliwości podstawowej (drganie)
	\item NHR, HNR (Noise to Harmonics Ratio, Harmonic to Noise Ratio) -  Dwa pomiary stosunku zakłóceń do harmonicznych
	\item Shimmer, Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, Shimmer:APQ11, Shimmer:DDA - pomiary zmiany amplitudy
	\item RPDE - Miara nieliniowej dynamicznej złożoności systemu
	\item DFA - (Detrended Fluctuation Analysis) Parametr opisujący samopodobieństwo sygnału
	\item PPE - Nieliniowa miara wariacji częstotliwości podostawowej
\end{itemize}

\begin{figure}
	\includegraphics[width=0.90\textwidth]{data.jpg}\par\vspace{1cm}
\caption{Wizualizacja zbioru uczącego}
\label{data visualisation}
\end{figure}

Celem projektu było określenie UPDRS motorycznego i całkowitego na podstawie dostępnych pomiarów parametru głosu pacjentów. Na rys \ref{data visualisation} przedstawiono zależność wszystkich parametrów od czasu dla pacjentów 1, 11, 21, 31 i 41. Na wykresach 1 i 2 przedstawiono motoryczny i całkowity UPDRS. Na wykresie 3 przedstawiono czas, stąd zaobserwowana zależność liniowa dla wszystkich pacjentów. Na wykresach 4 i 5 przedstawiono wiek i płeć pacjentów - stałe wartości w czasie pomiaru. Na pozostałych wykresach przedstawiono kolejne parametry związane z dźwiękiem wymienione powyżej.

\newpage
\section{Założenia eksperymentu}
Opis podziału na zbiory uczące i testowe.


\newpage

\section{Osiągnięte wyniki}
Wyniki eksperymentów bez zmniejszenia pacjentów i bez usunięcia duplikatów.

\subsection{Zmniejszenie liczby pacjentów}
Zaobserowano znaczącą poprawę osiąganych wyników przy zredukowanej liczbie pacjentów w zbiorach uczących i treningowych.

\subsection{Usunięcie duplikatów próbek}
Po przeanalizowaniu zawartości zbioru uczącego zauważono wiele powtarzających się próbek o bardzo zbliżonych wartościach czasu i sygnałów. 

Przykładowo dla pierwszego pacjenta w czasie: 5.6431, 5.6438, 5.6451, 5.6458, 5.6458 wartości jitter(\%) to 0.00348, 0.00413, 0.00217, 0.00294, 0.00250. Bardzo zbliżone wartości próbek mogą powodwać overfitting. Zbadano zachowanie i osiągane wyniki sieci dla co piątej próbki z dostępnego zbioru w zbiorze uczącym.

\subsection{Zmniejszenie liczby pacjentów i usunięcie duplikatów}
Połączenie poprzednich przypadków.

\newpage
\section{Wnioski}

Kilka spostrzeżeń:

\begin{itemize}
\item gdy mamy nieokrojone dane łatwo jest nauczyć sieć dla małej ilości pacjentów, dla dużej natomiast trwa to bardzo długo i efekty są mizerne
\item gdy mamy okrojone dane nie jest możliwe nauczenie sieci dla małej ilości pacjentów, dla dużej natomiast trwa to dość szybko, skuteczność natomiast jest średnia
\item trzeba zebrać dużo screenshotów
\item trzeba zweryfikować nabazgraną przeze mnie teorię, w szczególności backpropagation - nie jestem pewien, czy dokładnie taka postać jest wykorzystywana w RBF
\item trzeba poprawić estetykę tego sprawka
\end{itemize}

\newpage
\begin{thebibliography}{9}

\bibitem{zbioruczacy}
A Tsanas, MA Little, PE McSharry, LO Ramig (2009) 
'Accurate telemonitoring of Parkinson’s disease progression by non-invasive speech tests', 
IEEE Transactions on Biomedical Engineering (to appear). 
\\\texttt{https://archive.ics.uci.edu/ml/datasets/Parkinsons+\\Telemonitoring}

\bibitem{zbior-uczacy1}
Little MA, McSharry PE, Hunter EJ, Ramig LO (2009), 
'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', 
IEEE Transactions on Biomedical Engineering, 56(4):1015-1022 

\bibitem{zbior-uczacy2}
Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. 
'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', 
BioMedical Engineering OnLine, 26 June 2007

\bibitem{Osowski ujecie algorytmiczne}
Stanisław Osowski.
\textit{Sieci Neuronowe w ujęciu algorytmicznym}
Wydawnictwo Naukowo-Techniczne, Warszawa 1996

\bibitem{Osowski przetwarzanie informacji}
Stanisław Osowski.
\textit{Sieci Neuronowe do przetwarzania informacji}
Oficyna Wydawnicza Politechniki Warszawskiej, Warszawa 2006

\bibitem{Spread Constant}
Hongfa Wang, Xinai Xu, Zhejiang
Water Conservancy and Hydropower College
Determination of Spread Constant in RBF Neural Network by Genetic
Algorithm 
\textit{http://www.globalcis.org/ijact/ppl/IJACT3017PPL.pdf}

\bibitem{matlab}
Oficjalna dokumentacja Mathworks Deep Learning Toolbox. 
\\\texttt{https://www.mathworks.com/help/deeplearning/examples/radial-\\basis-approximation.html}

\bibitem{owards Data Sience}
Towards Data Science blog
\\\texttt{https://towardsdatascience.com/radial-basis-functions-neural-\\networks-all-we-need-to-know-9a88cc053448}


\end{thebibliography}
\newpage

\listoffigures
\newpage

\end{document}